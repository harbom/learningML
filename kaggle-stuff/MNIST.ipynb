{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A notebook for working on the kaggle MNIST digit recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimp\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in all the data\n",
    "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
    "\n",
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels=[\"label\"],axis=1) #drop the label column\n",
    "\n",
    "#free up space\n",
    "del train\n",
    "\n",
    "#g=sns.countplot(Y_train)\n",
    "#Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if any data is null\n",
    "X_train.isnull().any().describe()\n",
    "test.isnull().any().describe()\n",
    "\n",
    "#nothing is null, proceed as followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data --> convert to grayscale\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "#reshape data in 3 dimensions: height = 28px, width = 28px, depth = 1: 3D matrices to feed into Keras\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "#encode labels to vectors, so 2 is encoded as [0,0,1,0,0,0,0,0,0,0]\n",
    "Y_train = to_categorical(Y_train,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#split training and validation data\n",
    "random_seed = 2\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train,test_size=0.1,random_state=random_seed)\n",
    "\n",
    "g=plt.imshow(X_train[0][:,:,0])\n",
    "\n",
    "\n",
    "\n",
    "#preprocessing end ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: CNN. Using Keras Sequential API, adding 1 layer at a time.\n",
    "#first layer: convolutional (Conv2D) layer, a set of learnable filters to transform the image\n",
    "#second layer: pooling (MaxPool2D) layer, acts as a downsampling filter, looking at 2 neighboring pixels and choosing max value\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25)) #drops out 25% of model to prevent overfitting\n",
    "\n",
    "\n",
    "model.add(Flatten()) #flattens the matrix to 1 array: makes sense as this is the FC, the final layer in the CNN\n",
    "model.add(Dense(256, activation = \"relu\")) #Dense houses the activation functions\n",
    "model.add(Dropout(0.5)) #drop 50% of the data out\n",
    "model.add(Dense(10, activation = \"softmax\")) #nonlinear optimizer\n",
    "\n",
    "\n",
    "# need to define the optimizer to improve accuracy by minimizing losses\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer to make the optimizer converge faster\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "\n",
    "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286), a keras library\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 124s - loss: 0.5280 - accuracy: 0.8307 - val_loss: 0.0987 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haris\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
