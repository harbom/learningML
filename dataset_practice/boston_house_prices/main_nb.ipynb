{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the data\n",
    "\n",
    "reader = open(\"data.txt\",\"r\")\n",
    "\n",
    "columnNames = [\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\", \"PTRATIO\",\"B\",\"LSTAT\",\"MEDV\"]\n",
    "\n",
    "df = pd.DataFrame(columns = columnNames).astype(float)\n",
    "\n",
    "allArrays = []\n",
    "for i in reader:\n",
    "    splitArr = i.strip().split(\" \")\n",
    "    splitArr = [float(x) for x in splitArr if len(x)>0] #remove blank whitespaces from .split()\n",
    "    #print(splitArr)\n",
    "    allArrays.append(splitArr)\n",
    "reader.close()\n",
    "    \n",
    "for i in range(0,len(allArrays),2):\n",
    "    allArrays[i].extend(allArrays[i+1]) #add every 2nd list to first list (format of document)\n",
    "    newRowSeries = pd.Series(allArrays[i], index=df.columns) #convert to series\n",
    "    df = df.append(newRowSeries,ignore_index = True) #add to dataframe\n",
    "\n",
    "del allArrays #to free up space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start looking at data\n",
    "all_Y = df[\"MEDV\"]\n",
    "all_X = df.drop(\"MEDV\",axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(all_X,all_Y,random_state=42)\n",
    "\n",
    "#variables that I predict will have an impact\n",
    "crimes = all_X[\"CRIM\"]\n",
    "roomNum = all_X[\"RM\"]\n",
    "age = all_X[\"AGE\"]\n",
    "dis = all_X[\"DIS\"]\n",
    "b = all_X[\"B\"]\n",
    "ptratio = all_X[\"PTRATIO\"]\n",
    "#plt.hist(roomNum) #bell curve centered around 6, slightly slightly right skewed\n",
    "#plt.hist(crimes) #strongly skewed right, 0-10 makes up a majority of data, 10-20, 20-30, others\n",
    "#plt.hist(age) #skewed left: most vals from 80-100, 0-80 is approx uniform\n",
    "#plt.hist(dis) #very strongly skewed to the right, almost like a staircase\n",
    "#plt.hist(b) #very strongly skewed to the left, most of values in 350-400\n",
    "#plt.hist(ptratio) #bell curve around 18 with spikes at 22 and 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.416247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.405662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.060696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.039723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.015936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.013412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.012570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.011410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.011075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.006157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.003817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "LSTAT      0.416247\n",
       "RM         0.405662\n",
       "DIS        0.060696\n",
       "CRIM       0.039723\n",
       "PTRATIO    0.015936\n",
       "AGE        0.013412\n",
       "TAX        0.012570\n",
       "B          0.011410\n",
       "NOX        0.011075\n",
       "INDUS      0.006157\n",
       "RAD        0.003817\n",
       "ZN         0.002232\n",
       "CHAS       0.001062"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use feature importance to narrow down the important variables\n",
    "\n",
    "#train forest classifier on training data\n",
    "importance_regressor = RandomForestRegressor()\n",
    "importance_regressor.fit(X_train,Y_train) #fit the data on the training data\n",
    "importance_regressor.score(X_test,Y_test) #score the data based on testing data\n",
    "\n",
    "#add the feature importance in\n",
    "feature_importances = pd.DataFrame(importance_regressor.feature_importances_,\n",
    "                                   index = X_train.columns, columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "#after seing the dataframe, the most important columns are below\n",
    "columns = [\"RM\",\"LSTAT\"]\n",
    "\n",
    "#split between training and testing data\n",
    "X = all_X[columns]\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,all_Y,test_size=0.2,random_state=42)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls for the regression models\n",
    "\n",
    "#svm\n",
    "svm_model = svm.SVR(C=1.0,epsilon=0.2)\n",
    "svm_model.fit(X_train,Y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "#random forest\n",
    "rf_model = RandomForestRegressor(max_depth = 5, random_state=0)\n",
    "rf_model.fit(X_train,Y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "#linear regressor\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train,Y_train)\n",
    "lin_predictions = lin_model.predict(X_test)\n",
    "\n",
    "#ridge regression\n",
    "ridge_model = linear_model.Ridge(alpha=0.5)\n",
    "ridge_model.fit(X_train,Y_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "#bayesian regression\n",
    "bay_model = linear_model.BayesianRidge()\n",
    "bay_model.fit(X_train,Y_train)\n",
    "bay_predictions = bay_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm r squared:  0.6368684392843291\n",
      "random forest r squared:  0.7300307981564056\n",
      "linear regression r squared:  0.5739577415025857\n",
      "ridge r squared:  0.5742858090094847\n",
      "bayes r squared:  0.5752747722458944 \n",
      "\n",
      "svm MAE:  3.364327058962326\n",
      "random forest MAE  2.9508983305568717\n",
      "linear regression MAE  3.8987597213823584\n",
      "ridge MAE  3.8985289312589892\n",
      "bay MAE  3.8978173233194697\n"
     ]
    }
   ],
   "source": [
    "#look at the accuracy\n",
    "\n",
    "#R squared values\n",
    "print(\"svm r squared: \",r2_score(Y_test,svm_predictions))\n",
    "print(\"random forest r squared: \",r2_score(Y_test,rf_predictions))\n",
    "print(\"linear regression r squared: \",r2_score(Y_test,lin_predictions))\n",
    "print(\"ridge r squared: \",r2_score(Y_test,ridge_predictions))\n",
    "print(\"bayes r squared: \",r2_score(Y_test,bay_predictions),\"\\n\")\n",
    "\n",
    "#Mean absolute errors (MAE)\n",
    "print(\"svm MAE: \",mean_absolute_error(Y_test,svm_predictions))\n",
    "print(\"random forest MAE \",mean_absolute_error(Y_test,rf_predictions))\n",
    "print(\"linear regression MAE \",mean_absolute_error(Y_test,lin_predictions))\n",
    "print(\"ridge MAE \",mean_absolute_error(Y_test,ridge_predictions))\n",
    "print(\"bay MAE \",mean_absolute_error(Y_test,bay_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validations: \n",
      "\n",
      "svm:  0.2571762079516185\n",
      "random forest:  0.42891299656816634\n",
      "lin regression:  -0.03303612768229912\n"
     ]
    }
   ],
   "source": [
    "#make sure no overfit is happening by using cross validation\n",
    "svm_cvmodel = svm.SVR(C=1.0,epsilon=0.2)\n",
    "rf_cvmodel = RandomForestRegressor(max_depth = 5, random_state=0)\n",
    "lin_cvmodel = LinearRegression() #bayes and ridge regression are basically this anyways, will just use this to check CV\n",
    "\n",
    "print(\"cross validations: \\n\")\n",
    "scores = cross_val_score(svm_cvmodel,X,all_Y,cv=10,scoring=\"r2\") #gives 10 different scores\n",
    "print(\"svm: \",np.mean(scores))\n",
    "scores = cross_val_score(rf_cvmodel,X,all_Y,cv=10,scoring=\"r2\") #gives 10 different scores\n",
    "print(\"random forest: \",np.mean(scores))\n",
    "scores = cross_val_score(lin_cvmodel,X,all_Y,cv=10,scoring=\"r2\") #gives 10 different scores\n",
    "print(\"lin regression: \",np.mean(scores))\n",
    "\n",
    "#there does seem to be overfit..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
